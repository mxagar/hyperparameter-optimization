{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomized Search with Hyperopt\n",
    "\n",
    "In this notebook, we will perform **Randomized Search** to select the best **hyperparameters** for a Gradient Boosting Classifier, using the open source Python package [Hyperopt](http://hyperopt.github.io/hyperopt/).\n",
    "\n",
    "The randomized search is performed with the class **rand**.\n",
    "\n",
    "I find the documentation for Hyperopt quite unintuitive, so it helps to refer to the [original article](https://iopscience.iop.org/article/10.1088/1749-4699/8/1/014008/pdf) to understand the different parameters and classes.\n",
    "\n",
    "To step out of Scikit-learn, we will optimise the parameters of a Gradient Boosting Machine of the [xgboost package](https://xgboost.readthedocs.io/en/latest/python/python_intro.html).\n",
    "\n",
    "\n",
    "### Procedure\n",
    "\n",
    "To tune the hyper-parameters of our model we need to:\n",
    "\n",
    "- define a model\n",
    "- define the hyperparameter space\n",
    "- define the objective function we want to minimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from hyperopt import hp, rand, fmin, Trials\n",
    "\n",
    "# hp: define the hyperparameter space\n",
    "# rand: random search\n",
    "# fmin: optimization function\n",
    "# Trials: to evaluate the different searched hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0      1       2       3        4        5       6        7       8    \n",
       "0  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.3001  0.14710  0.2419  \\\n",
       "1  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869  0.07017  0.1812   \n",
       "2  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974  0.12790  0.2069   \n",
       "3  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414  0.10520  0.2597   \n",
       "4  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980  0.10430  0.1809   \n",
       "\n",
       "        9   ...     20     21      22      23      24      25      26      27   \n",
       "0  0.07871  ...  25.38  17.33  184.60  2019.0  0.1622  0.6656  0.7119  0.2654  \\\n",
       "1  0.05667  ...  24.99  23.41  158.80  1956.0  0.1238  0.1866  0.2416  0.1860   \n",
       "2  0.05999  ...  23.57  25.53  152.50  1709.0  0.1444  0.4245  0.4504  0.2430   \n",
       "3  0.09744  ...  14.91  26.50   98.87   567.7  0.2098  0.8663  0.6869  0.2575   \n",
       "4  0.05883  ...  22.54  16.67  152.20  1575.0  0.1374  0.2050  0.4000  0.1625   \n",
       "\n",
       "       28       29  \n",
       "0  0.4601  0.11890  \n",
       "1  0.2750  0.08902  \n",
       "2  0.3613  0.08758  \n",
       "3  0.6638  0.17300  \n",
       "4  0.2364  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "\n",
    "breast_cancer_X, breast_cancer_y = load_breast_cancer(return_X_y=True)\n",
    "X = pd.DataFrame(breast_cancer_X)\n",
    "y = pd.Series(breast_cancer_y).map({0:1, 1:0})\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.627417\n",
       "1    0.372583\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the target:\n",
    "# percentage of benign (0) and malign tumors (1)\n",
    "\n",
    "y.value_counts() / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((398, 30), (171, 30))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split dataset into a train and test set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Hyperparameter Space\n",
    "\n",
    "- [Hyperopt search space](http://hyperopt.github.io/hyperopt/getting-started/search_spaces/)\n",
    "\n",
    "- [xgb.XGBClassifier hyperparameters](https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.XGBClassifier)\n",
    "\n",
    "- [xgb general parameters](https://xgboost.readthedocs.io/en/latest/parameter.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the hyperparameter space\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': hp.quniform('n_estimators', 200, 2500, 100), # min, max, step\n",
    "    'max_depth': hp.uniform('max_depth', 1, 10), # min, max\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.99),\n",
    "    'booster': hp.choice('booster', ['gbtree', 'dart']),\n",
    "    'gamma': hp.quniform('gamma', 0.01, 10, 0.1),\n",
    "    'subsample': hp.uniform('subsample', 0.50, 0.90),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.50, 0.99),\n",
    "    'colsample_bylevel': hp.uniform('colsample_bylevel', 0.50, 0.99),\n",
    "    'colsample_bynode': hp.uniform('colsample_bynode', 0.50, 0.99),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 1, 20)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the objective function\n",
    "\n",
    "This is the hyperparameter response space, the function we want to minimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the objective function takes the hyperparameter space\n",
    "# as input\n",
    "\n",
    "def objective(params):\n",
    "\n",
    "    # we need a dictionary to indicate which value from the space\n",
    "    # to attribute to each value of the hyperparameter in the xgb\n",
    "    # here, we capture one parameter from the distributions\n",
    "    params_dict = {\n",
    "        'n_estimators': int(params['n_estimators']), # important int, as it takes integers only\n",
    "        'max_depth': int(params['max_depth']), # important int, as it takes integers only\n",
    "        'learning_rate': params['learning_rate'],\n",
    "        'booster': params['booster'],\n",
    "        'gamma': params['gamma'],\n",
    "        'subsample': params['subsample'],\n",
    "        'colsample_bytree': params['colsample_bytree'],\n",
    "        'colsample_bylevel': params['colsample_bylevel'],\n",
    "        'colsample_bynode': params['colsample_bynode'],\n",
    "        'random_state': 1000,\n",
    "    }\n",
    "\n",
    "    # with ** we pass the items in the dictionary as parameters\n",
    "    # to the xgb\n",
    "    gbm = xgb.XGBClassifier(**params_dict)\n",
    "\n",
    "    # train with cv\n",
    "    score = cross_val_score(gbm, X_train, y_train,\n",
    "                            scoring='accuracy', cv=5, n_jobs=4).mean()\n",
    "\n",
    "    # to minimize, we negate the score\n",
    "    return -score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomized Search\n",
    "\n",
    "[fmin](http://hyperopt.github.io/hyperopt/getting-started/minimizing_functions/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████| 50/50 [1:01:21<00:00, 73.62s/trial, best loss: -0.967373417721519]\n"
     ]
    }
   ],
   "source": [
    "# fmin performs the minimization\n",
    "# rand.suggest samples the parameters at random\n",
    "# i.e., performs the random search\n",
    "# NOTE: I got the error \"AttributeError: 'numpy.random._generator.Generator' object has no attribute 'randint'\"\n",
    "# So I needed to replace randint() with integers() in fmin.py\n",
    "search = fmin(\n",
    "    fn=objective,\n",
    "    space=param_grid,\n",
    "    max_evals=50, # number of combinations we'd like to randomly test\n",
    "    rstate=np.random.default_rng(42),\n",
    "    algo=rand.suggest,  # randomized search\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fmin returns a dictionary with the best parameters\n",
    "type(search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'booster': 0,\n",
       " 'colsample_bylevel': 0.5417218082785964,\n",
       " 'colsample_bynode': 0.6360624477042073,\n",
       " 'colsample_bytree': 0.9634914672712649,\n",
       " 'gamma': 3.4000000000000004,\n",
       " 'learning_rate': 0.8373466315069332,\n",
       " 'max_depth': 8.014045097149003,\n",
       " 'n_estimators': 900.0,\n",
       " 'reg_lambda': 4.390033483723911,\n",
       " 'subsample': 0.5507691346710539}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best hyperparameters\n",
    "search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create another dictionary to pass the search items as parameters\n",
    "# to a new xgb\n",
    "# we basically grab the best hyperparameters here and assure that the types\n",
    "# are correct\n",
    "best_hp_dict = {\n",
    "        'n_estimators': int(search['n_estimators']), # important int, as it takes integers only\n",
    "        'max_depth': int(search['max_depth']), # important int, as it takes integers only\n",
    "        'learning_rate': search['learning_rate'],\n",
    "        'booster': 'gbtree',\n",
    "        'gamma': search['gamma'],\n",
    "        'subsample': search['subsample'],\n",
    "        'colsample_bytree': search['colsample_bytree'],\n",
    "        'colsample_bylevel': search['colsample_bylevel'],\n",
    "        'colsample_bynode': search['colsample_bynode'],\n",
    "        'random_state': 1000,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=0.5417218082785964,\n",
       "              colsample_bynode=0.6360624477042073,\n",
       "              colsample_bytree=0.9634914672712649, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=3.4000000000000004, gpu_id=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.8373466315069332, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=8, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=900, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=1000, ...)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# after the search we can train the model with the\n",
    "# best parameters manually\n",
    "gbm_final = xgb.XGBClassifier(**best_hp_dict)\n",
    "gbm_final.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.992462311557789\n",
      "Test accuracy:  0.9766081871345029\n"
     ]
    }
   ],
   "source": [
    "# Final score on train and test splits\n",
    "X_train_preds = gbm_final.predict(X_train)\n",
    "X_test_preds = gbm_final.predict(X_test)\n",
    "print('Train accuracy: ', accuracy_score(y_train, X_train_preds))\n",
    "print('Test accuracy: ', accuracy_score(y_test, X_test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the search\n",
    "\n",
    "We can use Trials if we want to look into the search, and the performance values encountered during the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use the Trials() object to store more information from the search\n",
    "# for later inspection\n",
    "trials = Trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32%|██▏    | 16/50 [23:59<34:11, 60.35s/trial, best loss: -0.9623417721518986]"
     ]
    }
   ],
   "source": [
    "second_search = fmin(\n",
    "    fn=objective,\n",
    "    space=param_grid,\n",
    "    max_evals=50,\n",
    "    rstate=np.random.default_rng(42),\n",
    "    algo=rand.suggest,  # randomized search\n",
    "    trials=trials\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best hyperparameters\n",
    "second_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the best hyperparameters can also be found in\n",
    "# trials\n",
    "trials.argmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the search hyperparameter combinations\n",
    "pd.DataFrame(trials.vals).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the results\n",
    "pd.DataFrame(trials.results).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the results, sorted by loss = minimized score\n",
    "results = pd.concat([\n",
    "    pd.DataFrame(trials.vals),\n",
    "    pd.DataFrame(trials.results)],\n",
    "    axis=1,\n",
    ").sort_values(by='loss', ascending=False).reset_index(drop=True)\n",
    "\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the score as function of the hyperparameter combination\n",
    "results['loss'].plot()\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Hyperparam combination')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.9674050632911392"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Minimum/best score (recall we minimize)\n",
    "pd.DataFrame(trials.results)['loss'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
