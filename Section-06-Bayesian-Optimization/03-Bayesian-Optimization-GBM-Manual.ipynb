{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Optimization with Scikit-Optimize\n",
    "\n",
    "In this notebook, we will use **Bayesian Optimization** to select the best **hyperparameters** for a Gradient Boosting Classifier, using the open source Python package [Scikit-Optimize](https://scikit-optimize.github.io/stable/index.html).\n",
    "\n",
    "We will do the search manually, defining the objective function (hyperparameter response function ) and using the [Gaussian Process minimizer class from Scikit-optimize](\n",
    "https://scikit-optimize.github.io/stable/modules/generated/skopt.gp_minimize.html#skopt.gp_minimize).\n",
    "\n",
    "\n",
    "### Important\n",
    "\n",
    "Remember that we use **Bayesian Optimization** when we are looking to optimize functions that are costly, like those derived from neuronal networks. For a Gradient Boosting Machine trained on little data like the one in this notebook, we would probably make a better search if we carried out a Random Search.\n",
    "\n",
    "An example from scikit-optimize to optimize a regression can be found [here](https://scikit-optimize.github.io/stable/auto_examples/hyperparameter-optimization.html#sphx-glr-auto-examples-hyperparameter-optimization-py)\n",
    "\n",
    "\n",
    "### Hyperparameter Tunning Procedure\n",
    "\n",
    "To tune the hyper-parameters of our model we need to:\n",
    "\n",
    "- define a model\n",
    "- decide which parameters to optimize\n",
    "- define the objective function we want to minimize.\n",
    "\n",
    "\n",
    "### NOTE\n",
    "\n",
    "Scikit-Optimize will always **minimize** the objective function, so if we want to maximize a function, for example the roc-auc, we need to **negate** the metric. Thus, instead of maximizing the roc-auc, we minimize the -roc-auc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "\n",
    "from skopt import gp_minimize\n",
    "from skopt.plots import plot_convergence\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from skopt.utils import use_named_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0      1       2       3        4        5       6        7       8    \n",
       "0  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.3001  0.14710  0.2419  \\\n",
       "1  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869  0.07017  0.1812   \n",
       "2  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974  0.12790  0.2069   \n",
       "3  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414  0.10520  0.2597   \n",
       "4  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980  0.10430  0.1809   \n",
       "\n",
       "        9   ...     20     21      22      23      24      25      26      27   \n",
       "0  0.07871  ...  25.38  17.33  184.60  2019.0  0.1622  0.6656  0.7119  0.2654  \\\n",
       "1  0.05667  ...  24.99  23.41  158.80  1956.0  0.1238  0.1866  0.2416  0.1860   \n",
       "2  0.05999  ...  23.57  25.53  152.50  1709.0  0.1444  0.4245  0.4504  0.2430   \n",
       "3  0.09744  ...  14.91  26.50   98.87   567.7  0.2098  0.8663  0.6869  0.2575   \n",
       "4  0.05883  ...  22.54  16.67  152.20  1575.0  0.1374  0.2050  0.4000  0.1625   \n",
       "\n",
       "       28       29  \n",
       "0  0.4601  0.11890  \n",
       "1  0.2750  0.08902  \n",
       "2  0.3613  0.08758  \n",
       "3  0.6638  0.17300  \n",
       "4  0.2364  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "breast_cancer_X, breast_cancer_y = load_breast_cancer(return_X_y=True)\n",
    "X = pd.DataFrame(breast_cancer_X)\n",
    "y = pd.Series(breast_cancer_y).map({0:1, 1:0})\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.627417\n",
       "1    0.372583\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the target:\n",
    "# percentage of benign (0) and malign tumors (1)\n",
    "\n",
    "y.value_counts() / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((398, 30), (171, 30))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split dataset into a train and test set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=100)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "398"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isfinite(y_train).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "398"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isfinite(y_train.index.to_list()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isfinite(y_test).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isfinite(y_test.index.to_list()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Hyperparameter Space\n",
    "\n",
    "Scikit-optimize provides an utility function to create the range of values to examine for each hyperparameters. More details in [skopt.Space](https://scikit-optimize.github.io/stable/modules/generated/skopt.Space.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Integer(low=10, high=120, prior='uniform', transform='identity')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With Integer, we create a space of integers, sampled uniformly\n",
    "# between the minimum and maximum indicated values\n",
    "\n",
    "Integer(10, 120, name=\"n_estimators\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Real(low=0, high=0.999, prior='uniform', transform='identity')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With Real, we create a space of real values, sampled uniformly\n",
    "# between the minimum and maximum indicated values\n",
    "\n",
    "Real(0, 0.999, name=\"min_samples_split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Categorical(categories=('deviance', 'exponential'), prior=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With Categorical, we create a space of categories\n",
    "\n",
    "Categorical(['deviance', 'exponential'], name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# determine the hyperparameter space\n",
    "\n",
    "param_grid = [\n",
    "    Integer(10, 120, name=\"n_estimators\"),\n",
    "    Real(0.0001, 0.999, name=\"min_samples_split\"),\n",
    "    Integer(1, 5, name=\"max_depth\"),\n",
    "    Categorical(['log_loss', 'exponential'], name=\"loss\"),\n",
    "]\n",
    "\n",
    "# Scikit-optimize parameter grid is a list\n",
    "type(param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the gradient boosting classifier\n",
    "\n",
    "gbm = GradientBoostingClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the objective function\n",
    "\n",
    "This is the hyperparameter response space, the function we want to minimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We design a function to maximize the accuracy, of a GBM,\n",
    "# with cross-validation\n",
    "\n",
    "# the decorator allows our objective function to receive the parameters as\n",
    "# keyword arguments. This is a requirement of Scikit-Optimize.\n",
    "@use_named_args(param_grid)\n",
    "def objective(**params):\n",
    "    \n",
    "    # model with new parameters\n",
    "    gbm.set_params(**params)\n",
    "\n",
    "    # optimization function (hyperparam response function)\n",
    "    value = np.mean(\n",
    "        cross_val_score(\n",
    "            gbm, \n",
    "            X_train,\n",
    "            y_train,\n",
    "            cv=3,\n",
    "            n_jobs=-4,\n",
    "            scoring='accuracy')\n",
    "    )\n",
    "\n",
    "    # negate because we need to minimize\n",
    "    return -value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Optimization\n",
    "\n",
    "We are now ready for sequential model-based optimization. Here we use Gaussian process-based Optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_gb.py\", line 441, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_gb.py\", line 236, in _check_params\n",
      "    raise ValueError(\"Loss '{0:s}' not supported. \".format(self.loss))\n",
      "ValueError: Loss 'log_loss' not supported. \n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_gb.py\", line 441, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_gb.py\", line 236, in _check_params\n",
      "    raise ValueError(\"Loss '{0:s}' not supported. \".format(self.loss))\n",
      "ValueError: Loss 'log_loss' not supported. \n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_gb.py\", line 441, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_gb.py\", line 236, in _check_params\n",
      "    raise ValueError(\"Loss '{0:s}' not supported. \".format(self.loss))\n",
      "ValueError: Loss 'log_loss' not supported. \n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_gb.py\", line 441, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_gb.py\", line 236, in _check_params\n",
      "    raise ValueError(\"Loss '{0:s}' not supported. \".format(self.loss))\n",
      "ValueError: Loss 'log_loss' not supported. \n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_gb.py\", line 441, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_gb.py\", line 236, in _check_params\n",
      "    raise ValueError(\"Loss '{0:s}' not supported. \".format(self.loss))\n",
      "ValueError: Loss 'log_loss' not supported. \n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_gb.py\", line 441, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_gb.py\", line 236, in _check_params\n",
      "    raise ValueError(\"Loss '{0:s}' not supported. \".format(self.loss))\n",
      "ValueError: Loss 'log_loss' not supported. \n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_gb.py\", line 441, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_gb.py\", line 236, in _check_params\n",
      "    raise ValueError(\"Loss '{0:s}' not supported. \".format(self.loss))\n",
      "ValueError: Loss 'log_loss' not supported. \n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_gb.py\", line 441, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_gb.py\", line 236, in _check_params\n",
      "    raise ValueError(\"Loss '{0:s}' not supported. \".format(self.loss))\n",
      "ValueError: Loss 'log_loss' not supported. \n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_gb.py\", line 441, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_gb.py\", line 236, in _check_params\n",
      "    raise ValueError(\"Loss '{0:s}' not supported. \".format(self.loss))\n",
      "ValueError: Loss 'log_loss' not supported. \n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_gb.py\", line 441, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_gb.py\", line 236, in _check_params\n",
      "    raise ValueError(\"Loss '{0:s}' not supported. \".format(self.loss))\n",
      "ValueError: Loss 'log_loss' not supported. \n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_gb.py\", line 441, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_gb.py\", line 236, in _check_params\n",
      "    raise ValueError(\"Loss '{0:s}' not supported. \".format(self.loss))\n",
      "ValueError: Loss 'log_loss' not supported. \n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_gb.py\", line 441, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_gb.py\", line 236, in _check_params\n",
      "    raise ValueError(\"Loss '{0:s}' not supported. \".format(self.loss))\n",
      "ValueError: Loss 'log_loss' not supported. \n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_gb.py\", line 441, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_gb.py\", line 236, in _check_params\n",
      "    raise ValueError(\"Loss '{0:s}' not supported. \".format(self.loss))\n",
      "ValueError: Loss 'log_loss' not supported. \n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_gb.py\", line 441, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_gb.py\", line 236, in _check_params\n",
      "    raise ValueError(\"Loss '{0:s}' not supported. \".format(self.loss))\n",
      "ValueError: Loss 'log_loss' not supported. \n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_gb.py\", line 441, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_gb.py\", line 236, in _check_params\n",
      "    raise ValueError(\"Loss '{0:s}' not supported. \".format(self.loss))\n",
      "ValueError: Loss 'log_loss' not supported. \n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_gb.py\", line 441, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_gb.py\", line 236, in _check_params\n",
      "    raise ValueError(\"Loss '{0:s}' not supported. \".format(self.loss))\n",
      "ValueError: Loss 'log_loss' not supported. \n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_gb.py\", line 441, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_gb.py\", line 236, in _check_params\n",
      "    raise ValueError(\"Loss '{0:s}' not supported. \".format(self.loss))\n",
      "ValueError: Loss 'log_loss' not supported. \n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_gb.py\", line 441, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\msagardi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_gb.py\", line 236, in _check_params\n",
      "    raise ValueError(\"Loss '{0:s}' not supported. \".format(self.loss))\n",
      "ValueError: Loss 'log_loss' not supported. \n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# gp_minimize performs by default GP Optimization \u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# using a Marten Kernel\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m gp_ \u001b[38;5;241m=\u001b[39m \u001b[43mgp_minimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# the objective function to minimize\u001b[39;49;00m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# the hyperparameter space\u001b[39;49;00m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_initial_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# the number of points to evaluate f(x) to start of\u001b[39;49;00m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43macq_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEI\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# the acquisition function\u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# the number of subsequent evaluations of f(x)\u001b[39;49;00m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\hyp\\lib\\site-packages\\skopt\\optimizer\\gp.py:259\u001b[0m, in \u001b[0;36mgp_minimize\u001b[1;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs, model_queue_size)\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m base_estimator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    255\u001b[0m     base_estimator \u001b[38;5;241m=\u001b[39m cook_estimator(\n\u001b[0;32m    256\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGP\u001b[39m\u001b[38;5;124m\"\u001b[39m, space\u001b[38;5;241m=\u001b[39mspace, random_state\u001b[38;5;241m=\u001b[39mrng\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, np\u001b[38;5;241m.\u001b[39miinfo(np\u001b[38;5;241m.\u001b[39mint32)\u001b[38;5;241m.\u001b[39mmax),\n\u001b[0;32m    257\u001b[0m         noise\u001b[38;5;241m=\u001b[39mnoise)\n\u001b[1;32m--> 259\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbase_minimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    260\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    261\u001b[0m \u001b[43m    \u001b[49m\u001b[43macq_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43macq_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    262\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkappa\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkappa\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43macq_optimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43macq_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    263\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_points\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_random_starts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_random_starts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_initial_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_initial_points\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    265\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_point_generator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_point_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_restarts_optimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_restarts_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrng\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_queue_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\hyp\\lib\\site-packages\\skopt\\optimizer\\base.py:302\u001b[0m, in \u001b[0;36mbase_minimize\u001b[1;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs, model_queue_size)\u001b[0m\n\u001b[0;32m    300\u001b[0m next_x \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mask()\n\u001b[0;32m    301\u001b[0m next_y \u001b[38;5;241m=\u001b[39m func(next_x)\n\u001b[1;32m--> 302\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtell\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    303\u001b[0m result\u001b[38;5;241m.\u001b[39mspecs \u001b[38;5;241m=\u001b[39m specs\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m eval_callbacks(callbacks, result):\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\hyp\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:493\u001b[0m, in \u001b[0;36mOptimizer.tell\u001b[1;34m(self, x, y, fit)\u001b[0m\n\u001b[0;32m    490\u001b[0m         y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(y)\n\u001b[0;32m    491\u001b[0m         y[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m log(y[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m--> 493\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tell\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\hyp\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:536\u001b[0m, in \u001b[0;36mOptimizer._tell\u001b[1;34m(self, x, y, fit)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[0;32m    535\u001b[0m     warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 536\u001b[0m     \u001b[43mest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43myi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnext_xs_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39macq_func \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgp_hedge\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    539\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgains_ \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m est\u001b[38;5;241m.\u001b[39mpredict(np\u001b[38;5;241m.\u001b[39mvstack(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext_xs_))\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\hyp\\lib\\site-packages\\skopt\\learning\\gaussian_process\\gpr.py:195\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnoise:\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel \u001b[38;5;241m+\u001b[39m WhiteKernel(\n\u001b[0;32m    193\u001b[0m         noise_level\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnoise, noise_level_bounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfixed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    194\u001b[0m     )\n\u001b[1;32m--> 195\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mGaussianProcessRegressor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnoise_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnoise:\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;66;03m# The noise component of this kernel should be set to zero\u001b[39;00m\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;66;03m# while estimating K(X_test, X_test)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;66;03m# http://www.gaussianprocess.org/gpml/chapters/RW2.pdf\u001b[39;00m\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;66;03m# Hence this hack\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\gaussian_process\\_gpr.py:189\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rng \u001b[38;5;241m=\u001b[39m check_random_state(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state)\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_\u001b[38;5;241m.\u001b[39mrequires_vector_input:\n\u001b[1;32m--> 189\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnumeric\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    192\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, y, multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, y_numeric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    193\u001b[0m                                ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py:432\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    430\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    431\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 432\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    433\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\validation.py:72\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPass \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m as keyword args. From version 0.25 \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     68\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassing these as positional arguments will \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     69\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult in an error\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(args_msg)),\n\u001b[0;32m     70\u001b[0m                   \u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[0;32m     71\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mupdate({k: arg \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args)})\n\u001b[1;32m---> 72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\validation.py:804\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    795\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(X, accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m    796\u001b[0m                 accept_large_sparse\u001b[38;5;241m=\u001b[39maccept_large_sparse,\n\u001b[0;32m    797\u001b[0m                 dtype\u001b[38;5;241m=\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39morder, copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    801\u001b[0m                 ensure_min_features\u001b[38;5;241m=\u001b[39mensure_min_features,\n\u001b[0;32m    802\u001b[0m                 estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m    803\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m multi_output:\n\u001b[1;32m--> 804\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    805\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    806\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    807\u001b[0m     y \u001b[38;5;241m=\u001b[39m column_or_1d(y, warn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\validation.py:72\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPass \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m as keyword args. From version 0.25 \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     68\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassing these as positional arguments will \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     69\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult in an error\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(args_msg)),\n\u001b[0;32m     70\u001b[0m                   \u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[0;32m     71\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mupdate({k: arg \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args)})\n\u001b[1;32m---> 72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\validation.py:644\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    640\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    641\u001b[0m                          \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name))\n\u001b[0;32m    643\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 644\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    645\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    647\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    648\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\validation.py:96\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (allow_nan \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39misinf(X)\u001b[38;5;241m.\u001b[39many() \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m     94\u001b[0m             \u001b[38;5;129;01mnot\u001b[39;00m allow_nan \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(X)\u001b[38;5;241m.\u001b[39mall()):\n\u001b[0;32m     95\u001b[0m         type_err \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minfinity\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m allow_nan \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNaN, infinity\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 96\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     97\u001b[0m                 msg_err\u001b[38;5;241m.\u001b[39mformat\n\u001b[0;32m     98\u001b[0m                 (type_err,\n\u001b[0;32m     99\u001b[0m                  msg_dtype \u001b[38;5;28;01mif\u001b[39;00m msg_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m    100\u001b[0m         )\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# for object dtype data, we only check for NaNs (GH-13254)\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nan:\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "# gp_minimize performs by default GP Optimization \n",
    "# using a Marten Kernel\n",
    "\n",
    "gp_ = gp_minimize(\n",
    "    objective, # the objective function to minimize\n",
    "    param_grid, # the hyperparameter space\n",
    "    n_initial_points=10, # the number of points to evaluate f(x) to start of\n",
    "    acq_func='EI', # the acquisition function\n",
    "    n_calls=50, # the number of subsequent evaluations of f(x)\n",
    "    random_state=0, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Best score=-0.9749'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function value at the minimum.\n",
    "# note that it is the negative of the accuracy\n",
    "\"Best score=%.4f\" % gp_.fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:\n",
      "=========================\n",
      "- n_estimators=118\n",
      "- min_samples_split=0.733826\n",
      "- max_depth=5\n",
      "- loss = exponential\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"Best parameters:\n",
    "=========================\n",
    "- n_estimators=%d\n",
    "- min_samples_split=%.6f\n",
    "- max_depth=%d\n",
    "- loss = %s\"\"\" % (gp_.x[0], \n",
    "                gp_.x[1],\n",
    "                gp_.x[2],\n",
    "                gp_.x[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate convergence of the search\n",
    "\n",
    "[plot_convergence](https://scikit-optimize.github.io/stable/modules/generated/skopt.plots.plot_convergence.html#skopt.plots.plot_convergence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Convergence plot'}, xlabel='Number of calls $n$', ylabel='$\\\\min f(x)$ after $n$ calls'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_convergence(gp_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that with around 20 iterations, the procedure already found the minimum of the hyperparamter response function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
